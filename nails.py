# -*- coding: utf-8 -*-
"""Nails.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_elutXdA-EcbC1-labt8TExRzEcgxWdS

# **Preprocessing**

##Import data
"""

!pip install kaggle

from google.colab import files

files.upload()

!mkdir kaggle
!mv kaggle.json kaggle

!chmod 600 /content/kaggle/kaggle.json

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/kaggle"

!kaggle datasets download -d nuttidalapthanachai/nails-new-test

!mkdir nail-dataset && unzip -q nails-new-test.zip -d nail-dataset

import tensorflow as tf

Adam = tf.keras.optimizers.Adam
to_categorical = tf.keras.utils.to_categorical
ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator
ReduceLROnPlateau = tf.keras.callbacks.ReduceLROnPlateau
load_img = tf.keras.preprocessing.image.load_img
img_to_array = tf.keras.preprocessing.image.img_to_array
array_to_img = tf.keras.preprocessing.image.array_to_img

from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import plotly.graph_objs as go
from plotly import subplots
import plotly

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout, BatchNormalization
from tensorflow.keras.models import load_model
from tensorflow.keras.callbacks import ModelCheckpoint

import pandas as pd
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import pickle as p

import warnings
warnings.filterwarnings('ignore')

img_rows = 100
img_cols = 100

import cv2
import os
import random
import matplotlib.pyplot as plt
import numpy as np

DIRECTORY_DATASET = r'/content/nail-dataset'
CATEGORIES = ["beau's line",'black line','clubbing',"muehrck-e's lines",'onycholysis',"terry's nail",'white spot']

Data=[]

filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])

for category in CATEGORIES:
  folder = os.path.join(DIRECTORY_DATASET, category)
  label = CATEGORIES.index(category)
  for img in os.listdir(folder): 
    img_path = os.path.join(folder, img)
    img_arr = cv2.imread(img_path)
    img_arr = cv2.resize(img_arr, (img_rows, img_cols))
    img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
    img_arr = cv2.filter2D(img_arr,-1,filter)
    img_arr = img_arr[5:95,5:95]
    
    Data.append([img_arr, label])

print(len(Data))

"""##แบ่งข้อมูลตาม class"""

beau = []
black = []
club = []
mees = []
ony = []
terry = []
white = []

for i in range(len(Data)):
  if Data[i][1] == 0:
    beau.append(Data[i])
  if Data[i][1] == 1:
    black.append(Data[i])
  elif Data[i][1] == 2:
    club.append(Data[i])
  elif Data[i][1] == 3:
    mees.append(Data[i])
  elif Data[i][1] == 4:
    ony.append(Data[i])
  elif Data[i][1] == 5:
    terry.append(Data[i])
  elif Data[i][1] == 6:
    white.append(Data[i])

"""##Split data"""

train_beau, test_beau = train_test_split(beau, test_size=0.2, shuffle=True,random_state=1)
train_black, test_black = train_test_split(black, test_size=0.2, shuffle=True,random_state=1)
train_club, test_club = train_test_split(club, test_size=0.2, shuffle=True,random_state=1)
train_mees, test_mees = train_test_split(mees, test_size=0.2, shuffle=True,random_state=1)
train_ony, test_ony = train_test_split(ony, test_size=0.2, shuffle=True,random_state=1)
train_terry, test_terry = train_test_split(terry, test_size=0.2, shuffle=True,random_state=1)
train_white, test_white = train_test_split(white, test_size=0.2, shuffle=True,random_state=1)

train_data = np.vstack((train_beau,train_black,train_club,train_mees,train_ony,train_terry,train_white))
test_data = np.vstack((test_beau,test_black,test_club,test_mees,test_ony,test_terry,test_white))

print(len(train_data))
print(len(test_data))

train = []
y = []
test = []
y_test = []

for features, labels in train_data:
  train.append(features)
  y.append(labels)

for features, labels in test_data:
  test.append(features)
  y_test.append(labels)

train = np.array(train)
y = np.array(y)

test = np.array(test)
y_test = np.array(y_test)

print("nali train -  rows:",train.shape[0]," columns:", train.shape[1], " rows:", train.shape[2])
print("nail test -  rows:",test.shape[0]," columns:", test.shape[1], " rows:", test.shape[2])

for i in range(7):
    j=80*i
    ax = plt.subplot(2, 4, 1+i)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_title('%s'%(CATEGORIES[int(y[80*i])]))
    plt.imshow(train[j])
    # plt.imshow(train[i])

plt.tight_layout()
plt.savefig('nail.png', dpi=300)
plt.axis('off')

img_cols = 90
img_rows = 90

print(train.shape, test.shape)

train = train.reshape((train.shape[0],  img_rows, img_cols, 3))
test = test.reshape((test.shape[0],  img_rows, img_cols, 3))

print(train.shape, test.shape)

train = train / 255.0
test = test / 255.0

print(y.shape, y_test.shape)
print(y[:10])

y = to_categorical(y)
y_test = to_categorical(y_test)

print(y.shape, y_test.shape)
y[:10]

x_train, x_val, y_train, y_val = train_test_split(train, y, test_size = 0.2 ,shuffle=True, random_state = 99)
x_train.shape, x_val.shape, y_train.shape, y_val.shape

import tensorflow as tf
fashion_mnist = tf.keras.datasets.fashion_mnist
to_categorical = tf.keras.utils.to_categorical

import matplotlib.pyplot as plt
from sklearn.datasets import make_circles
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

import plotly.express as px
import plotly
import plotly.graph_objs as go
import plotly.figure_factory as ff
import seaborn as sn

from collections import Counter

"""# **Baseline model**"""

# model = Sequential()
model = tf.keras.Sequential()

#1. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(img_rows, img_cols, 3)))
model.add(tf.keras.layers.Activation("relu"))

#2. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.Activation("relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=(5, 5)))

#3. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.Activation("relu"))

#4. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.Activation("relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=(5, 5)))

#FULLY CONNECTED LAYER
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256))
model.add(tf.keras.layers.Activation("relu"))

#OUTPUT LAYER
model.add(tf.keras.layers.Dense(7, activation='softmax'))

optimizer = Adam()
model.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics=["accuracy"])

model.summary()

learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.1, min_lr=0.00001)
callbacks_list = [learning_rate_reduction]

EPOCHS = 1000
BATCH_SIZE = 32

history = model.fit(x_train, y_train,
                  batch_size= BATCH_SIZE,
                  epochs= EPOCHS,
                  # shuffle=True,
                  verbose = 1,
                  validation_data=(x_val, y_val))

h1 = go.Scatter(y=history.history['accuracy'], 
                    mode="lines", line=dict(
                    width=2,
                    color='Green'),
                    name="acc"
                   )
h2 = go.Scatter(y=history.history['val_accuracy'], 
                    mode="lines", line=dict(
                    width=2,
                    color='red'),
                    name="val_acc"
                   )

data = [h1,h2]
layout1 = go.Layout(title='Accuracy',
                   xaxis=dict(title='epochs'),
                   yaxis=dict(title=''))
fig1 = go.Figure(data = data, layout=layout1)
plotly.offline.iplot(fig1)

h1 = go.Scatter(y=history.history['loss'], 
                    mode="lines",
                    line=dict(
                        width=2,
                        color='Blue'),
                        name="loss"
                   )
h2 = go.Scatter(y=history.history['val_loss'], 
                    mode="lines",
                    line=dict(
                        width=2,
                        color='Magenta'),
                        name="val_loss"
                   )

data = [h1,h2]
layout1 = go.Layout(title='Loss',
                   xaxis=dict(title='epochs'),
                   yaxis=dict(title=''))
fig1 = go.Figure(data = data, layout=layout1)
plotly.offline.iplot(fig1)

!pip install visualkeras
import visualkeras
visualkeras.layered_view(model).show() # display using your system viewer
visualkeras.layered_view(model, to_file='output.png') # write to disk
visualkeras.layered_view(model, to_file='output.png').show() # write and show
# visualkeras.graph_view()
# import tkinter as tk  
# from tkinter import ttk,font  
# # visualkeras.layered_view(model)
from PIL import ImageFont
# # font = ImageFont.load("arial.ttf")
font = ImageFont.load_default()
# # font = ImageFont.truetype("msyhbd.ttf", 32)  # using comic sans is strictly prohibited!
visualkeras.layered_view(model, legend=True, font=font)

score = model.evaluate(test, y_test, verbose = 0)
print("Test Loss:",score[0])
print("Test Accuracy:",score[1])

predicted_classes = model.predict(test)
predicted_classes = np.argmax(predicted_classes,axis = 1)

y_true = np.argmax(y_test,axis = 1)

c = Counter(y_true)
c

cm = confusion_matrix(y_true, predicted_classes)
np.savetxt("confusion_matrix.csv", cm, delimiter=",")
cm

labels = ["Be",'Bl','Cl',"Mu",'On',"Te",'Wh']

def cm_plot(cm, labels):
    x = labels
    y = labels

    z_text = [[str(y) for y in x] for x in cm]
    fig = ff.create_annotated_heatmap(cm, x=x, y=y, annotation_text=z_text, colorscale='blues')

    fig.update_layout(title_text='Confusion Matrix')

    fig.add_annotation(dict(font=dict(color="black",size=13),
                            x=0.5,
                            y=-0.15,
                            showarrow=False,
                            text="Predicted Value",
                            xref="paper",
                            yref="paper"
                           ))

    fig.add_annotation(dict(font=dict(color="black",size=13),
                            x=-0.20,
                            y=0.5,
                            showarrow=False,
                            text="Real Value",
                            textangle=-90,
                            xref="paper",
                            yref="paper"
                           ))

    fig.update_layout(margin=dict(t=50, l=200))
    fig['layout']['yaxis']['autorange'] = "reversed"

    fig['data'][0]['showscale'] = True
    fig.show()

cm_plot(cm, labels)

report = classification_report(y_true, predicted_classes, target_names=labels, digits=4)
print(report)

predicted_score = model.predict(test)
predicted_score.shape, y_test.shape

hovertemplate = 'False Positive Rate=%{x:.4f}<br>True Positive Rate=%{y:.4f}<br>Threshold=%{text:.4f}'
fig = go.Figure()
fig.add_shape(
    type='line', line=dict(dash='dash'),
    x0=0, x1=1, y0=0, y1=1
)

for i in range(predicted_score.shape[1]):
    y_real = y_test[:, i]
    y_score = predicted_score[:, i]

    fpr, tpr, threshold = roc_curve(y_real, y_score)
    auc_score = auc(fpr, tpr)

    name = f"{labels[i]}, AUC={auc_score:.4f}"
    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines', text=threshold, hovertemplate=hovertemplate))

fig.update_layout(
    title='ROC Curve and AUC',
    xaxis_title='False Positive Rate',
    yaxis_title='True Positive Rate',
)

fig.show()

"""# **Drop out** """

datagen = ImageDataGenerator(
    # rotation_range=25, width_shift_range=0.1,
    # height_shift_range=0.1, shear_range=0.2, 
    # zoom_range=0.2,horizontal_flip=True, 
    # fill_mode="nearest"
        rotation_range=0.05,    #Randomly rotate images in the range
        zoom_range=0.3,         #Randomly zoom image
        width_shift_range=0.1,  #Randomly shift images horizontally
        height_shift_range=0.1, #Randomly shift images vertically
        shear_range=0.05        #Randomly shear images
        )

datagen.fit(x_train)

# model = Sequential()
model = tf.keras.Sequential()

#1. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same', input_shape=(img_rows, img_cols, 3)))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.1))

#2. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=(5, 5)))
model.add(tf.keras.layers.Dropout(0.1))

#3. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.1))

#4. CNN LAYER
model.add(tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same'))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))

model.add(tf.keras.layers.MaxPool2D(pool_size=(5, 5)))
model.add(tf.keras.layers.Dropout(0.1))


#FULLY CONNECTED LAYER
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(256))
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Activation("relu"))
model.add(tf.keras.layers.Dropout(0.1))

#OUTPUT LAYER
model.add(tf.keras.layers.Dense(7, activation='softmax'))

optimizer = Adam(learning_rate = 0.0001)
model.compile(optimizer = optimizer, loss = "categorical_crossentropy", metrics=["accuracy"])

model.summary()

EPOCHS = 1000
BATCH_SIZE = 10

history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),
                              shuffle=True,
                              epochs= EPOCHS,
                              # callbacks=callbacks_list, 
                              validation_data = (x_val, y_val),
                              verbose = 1, 
                              steps_per_epoch=x_train.shape[0] // BATCH_SIZE)

h1 = go.Scatter(y=history.history['accuracy'], 
                    mode="lines", line=dict(
                    width=2,
                    color='Green'),
                    name="acc"
                   )
h2 = go.Scatter(y=history.history['val_accuracy'], 
                    mode="lines", line=dict(
                    width=2,
                    color='red'),
                    name="val_acc"
                   )

data = [h1,h2]
layout1 = go.Layout(title='Accuracy',
                   xaxis=dict(title='epochs'),
                   yaxis=dict(title=''))
fig1 = go.Figure(data = data, layout=layout1)
plotly.offline.iplot(fig1)

h1 = go.Scatter(y=history.history['loss'], 
                    mode="lines",
                    line=dict(
                        width=2,
                        color='Blue'),
                        name="loss"
                   )
h2 = go.Scatter(y=history.history['val_loss'], 
                    mode="lines",
                    line=dict(
                        width=2,
                        color='Magenta'),
                        name="val_loss"
                   )

data = [h1,h2]
layout1 = go.Layout(title='Loss',
                   xaxis=dict(title='epochs'),
                   yaxis=dict(title=''))
fig1 = go.Figure(data = data, layout=layout1)
plotly.offline.iplot(fig1)

# !pip install visualkeras
import visualkeras
visualkeras.layered_view(model).show() # display using your system viewer
visualkeras.layered_view(model, to_file='output.png') # write to disk
visualkeras.layered_view(model, to_file='output.png').show() # write and show
# visualkeras.graph_view()
# import tkinter as tk  
# from tkinter import ttk,font  
# # visualkeras.layered_view(model)
from PIL import ImageFont
# # font = ImageFont.load("arial.ttf")
font = ImageFont.load_default()
# # font = ImageFont.truetype("msyhbd.ttf", 32)  # using comic sans is strictly prohibited!
visualkeras.layered_view(model, legend=True, font=font)

score = model.evaluate(test, y_test, verbose = 0)
print("Test Loss:",score[0])
print("Test Accuracy:",score[1])

predicted_classes = model.predict(test)
predicted_classes = np.argmax(predicted_classes,axis = 1)

y_true = np.argmax(y_test,axis = 1)

c = Counter(y_true)
c

cm = confusion_matrix(y_true, predicted_classes)
np.savetxt("confusion_matrix.csv", cm, delimiter=",")
cm

# import seaborn as sn
# import matplotlib.pyplot as plt

# df_cm = pd.DataFrame(cm, range(7), range(7))
# plt.figure(figsize=(12,8))
# sn.set(font_scale=1.3) # for label size
# sn.heatmap(df_cm, annot=True, annot_kws={"size": 13}, fmt='g') # for num predict size

# plt.show()

cm_plot(cm, labels)

report = classification_report(y_true, predicted_classes, target_names=CATEGORIES, digits=4)
print(report)

predicted_score = model.predict(test)
predicted_score.shape, y_test.shape

hovertemplate = 'False Positive Rate=%{x:.4f}<br>True Positive Rate=%{y:.4f}<br>Threshold=%{text:.4f}'
fig = go.Figure()
fig.add_shape(
    type='line', line=dict(dash='dash'),
    x0=0, x1=1, y0=0, y1=1
)

for i in range(predicted_score.shape[1]):
    y_real = y_test[:, i]
    y_score = predicted_score[:, i]

    fpr, tpr, threshold = roc_curve(y_real, y_score)
    auc_score = auc(fpr, tpr)

    name = f"{labels[i]}, AUC={auc_score:.4f}"
    fig.add_trace(go.Scatter(x=fpr, y=tpr, name=name, mode='lines', text=threshold, hovertemplate=hovertemplate))

fig.update_layout(
    title='ROC Curve and AUC',
    xaxis_title='False Positive Rate',
    yaxis_title='True Positive Rate',
)

fig.show()